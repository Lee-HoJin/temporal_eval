import pandas as pd
import numpy as np

import metadata

def load_and_preprocess_data(data_path, metadata, parent_table_name, child_table_name):
    """ë¶€ëª¨-ìì‹ í…Œì´ë¸”ì„ ë¡œë“œí•˜ê³  ë³‘í•© ë° ì „ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    
    rels = metadata.get_relationships(parent_table_name)
    
    try:
        # 2. ë¦¬ìŠ¤íŠ¸ ì•ˆì—ì„œ í˜„ì¬ ì‘ì—…í•˜ë ¤ëŠ” child_table_nameê³¼ ì¼ì¹˜í•˜ëŠ” ê´€ê³„ í•˜ë‚˜ë¥¼ ì°¾ìŒ
        relationship = next(r for r in rels if r['child_table_name'] == child_table_name)
        
        # 3. ì°¾ì€ ë”•ì…”ë„ˆë¦¬ì—ì„œ í‚¤ ì¶”ì¶œ
        parent_key = relationship['parent_primary_key']
        child_key = relationship['child_foreign_key']
        
        print(f"ë§¤í•‘ í™•ì¸: {parent_table_name}({parent_key}) -> {child_table_name}({child_key})")
        
    except StopIteration:
        print(f"Error: {parent_table_name}ì™€ {child_table_name} ì‚¬ì´ì˜ ê´€ê³„ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # datetime_colì„ ë¯¸ë¦¬ ì´ˆê¸°í™” (ì°¸ì¡° ì—ëŸ¬ ë°©ì§€)
    datetime_col = None
    
    try:
        parent_df = pd.read_csv(data_path + f"{parent_table_name}.csv")
        child_df = pd.read_csv(data_path + f"{child_table_name}.csv")
    except FileNotFoundError:
        print(f"Warning: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ - {data_path}")
        return None

    # í‚¤ê°€ ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
    if parent_key not in parent_df.columns:
        print(f"Error: Parent key '{parent_key}' not found in {parent_table_name}.csv")
        return None
    
    if child_key not in child_df.columns:
        print(f"Error: Child key '{child_key}' not found in {child_table_name}.csv")
        return None

    # í‚¤ ì»¬ëŸ¼ì˜ ë°ì´í„° íƒ€ì… í†µì¼ (ë” ì•ˆì „í•œ ë°©ì‹)
    original_parent_key = parent_df[parent_key].copy()
    original_child_key = child_df[child_key].copy()
    
    # ë¨¼ì € ìˆ«ì ë³€í™˜ ì‹œë„
    try:
        parent_numeric = pd.to_numeric(parent_df[parent_key], errors='coerce')
        child_numeric = pd.to_numeric(child_df[child_key], errors='coerce')
        
        # NaNì´ ë„ˆë¬´ ë§ì´ ìƒê¸°ë©´ ìˆ«ì ë³€í™˜ í¬ê¸°
        parent_nan_ratio = parent_numeric.isna().sum() / len(parent_numeric)
        child_nan_ratio = child_numeric.isna().sum() / len(child_numeric)
        
        if parent_nan_ratio > 0.1 or child_nan_ratio > 0.1:  # 10% ì´ìƒ NaNì´ë©´ í¬ê¸°
            print(f"ìˆ«ì ë³€í™˜ ì‹œ NaN ë¹„ìœ¨ì´ ë†’ìŒ (Parent: {parent_nan_ratio:.2%}, Child: {child_nan_ratio:.2%})")
            print("ë¬¸ìì—´ ë³€í™˜ì„ ì‹œë„í•©ë‹ˆë‹¤.")
            
            # ë¬¸ìì—´ë¡œ ë³€í™˜
            parent_df[parent_key] = original_parent_key.astype(str)
            child_df[child_key] = original_child_key.astype(str)
            print(f"í‚¤ ì»¬ëŸ¼ì„ ë¬¸ìì—´ë¡œ ë³€í™˜: {parent_key}, {child_key}")
        else:
            # ìˆ«ì ë³€í™˜ ì„±ê³µ
            parent_df[parent_key] = parent_numeric
            child_df[child_key] = child_numeric
            print(f"í‚¤ ì»¬ëŸ¼ì„ ìˆ«ìë¡œ ë³€í™˜: {parent_key}, {child_key}")
            
    except Exception as e:
        print(f"í‚¤ ë³€í™˜ ì‹¤íŒ¨, ì›ë³¸ ìœ ì§€: {e}")
        # ë³€í™˜ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ìœ ì§€
        parent_df[parent_key] = original_parent_key
        child_df[child_key] = original_child_key
    
    print(f"ë³€í™˜ í›„ - Parent key '{parent_key}' dtype: {parent_df[parent_key].dtype}")
    
    # === ë³‘í•© ì „ ì§„ë‹¨ ì •ë³´ ===
    print(f"\n=== ë³‘í•© ì „ ì§„ë‹¨ ===")
    print(f"Parent í…Œì´ë¸” í¬ê¸°: {len(parent_df)} í–‰")
    print(f"Child í…Œì´ë¸” í¬ê¸°: {len(child_df)} í–‰")
        
    # ìœ íš¨í•œ ê°’ë§Œìœ¼ë¡œ ê³ ìœ ê°’ ê³„ì‚°
    parent_valid = parent_df[parent_key].dropna()
    child_valid = child_df[child_key].dropna()
    
    print(f"Parent key '{parent_key}' ìœ íš¨í•œ ê³ ìœ ê°’ ìˆ˜: {parent_valid.nunique()}")
    print(f"Child key '{child_key}' ìœ íš¨í•œ ê³ ìœ ê°’ ìˆ˜: {child_valid.nunique()}")
    
    if len(parent_valid) == 0 or len(child_valid) == 0:
        print("ğŸš¨ ERROR: ìœ íš¨í•œ í‚¤ ê°’ì´ ì—†ìŠµë‹ˆë‹¤. ë³‘í•© ë¶ˆê°€ëŠ¥.")
        return None
    
    # ê³µí†µ í‚¤ í™•ì¸ (NaN ì œì™¸)
    parent_keys = set(parent_valid)
    child_keys = set(child_valid)
    common_keys = parent_keys.intersection(child_keys)
    print(f"ê³µí†µ í‚¤ ê°œìˆ˜: {len(common_keys)}")
    
    if len(common_keys) == 0:
        print("ğŸš¨ ERROR: ê³µí†µ í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        print(f"Parent í‚¤ ìƒ˜í”Œ: {list(parent_keys)[:10]}")
        print(f"Child í‚¤ ìƒ˜í”Œ: {list(child_keys)[:10]}")
        
        # ë°©ë²• 1: ì¹´í…Œê³ ë¦¬ ì¸ì½”ë”©ì„ í†µí•œ í‚¤ í†µì¼ ì‹œë„
        print("ë°©ë²• 1: ì¹´í…Œê³ ë¦¬ ì¸ì½”ë”©ì„ í†µí•œ í‚¤ í†µì¼ ì‹œë„...")
        
        try:
            # ëª¨ë“  í‚¤ ê°’ì„ í•©ì³ì„œ ê³µí†µ ì¹´í…Œê³ ë¦¬ ìƒì„±
            all_keys = list(parent_keys) + list(child_keys)
            unique_keys = sorted(set(all_keys))
            print(f"ì „ì²´ ê³ ìœ  í‚¤ ê°œìˆ˜: {len(unique_keys)}")
            
            # ì¹´í…Œê³ ë¦¬ ìƒì„±
            key_categories = pd.Categorical(unique_keys).categories
            
            # Parent í‚¤ë¥¼ ì¹´í…Œê³ ë¦¬ ì½”ë“œë¡œ ë³€í™˜
            parent_cat = pd.Categorical(parent_df[parent_key], categories=key_categories)
            parent_df_encoded = parent_df.copy()
            parent_df_encoded[parent_key + '_encoded'] = parent_cat.codes
            
            # Child í‚¤ë¥¼ ì¹´í…Œê³ ë¦¬ ì½”ë“œë¡œ ë³€í™˜  
            child_cat = pd.Categorical(child_df[child_key], categories=key_categories)
            child_df_encoded = child_df.copy()
            child_df_encoded[child_key + '_encoded'] = child_cat.codes
            
            # -1 (missing category) ì œê±°
            parent_df_encoded = parent_df_encoded[parent_df_encoded[parent_key + '_encoded'] != -1]
            child_df_encoded = child_df_encoded[child_df_encoded[child_key + '_encoded'] != -1]
            
            print(f"ì¸ì½”ë”© í›„ Parent í¬ê¸°: {len(parent_df_encoded)} í–‰")
            print(f"ì¸ì½”ë”© í›„ Child í¬ê¸°: {len(child_df_encoded)} í–‰")
            
            if len(parent_df_encoded) > 0 and len(child_df_encoded) > 0:
                # ì¸ì½”ë”©ëœ í‚¤ë¡œ ê³µí†µ í‚¤ í™•ì¸
                parent_encoded_keys = set(parent_df_encoded[parent_key + '_encoded'])
                child_encoded_keys = set(child_df_encoded[child_key + '_encoded'])
                common_encoded_keys = parent_encoded_keys.intersection(child_encoded_keys)
                
                print(f"ì¸ì½”ë”© í›„ ê³µí†µ í‚¤ ê°œìˆ˜: {len(common_encoded_keys)}")
                
                if len(common_encoded_keys) > 0:
                    # ì¸ì½”ë”©ëœ í‚¤ë¡œ ë³‘í•©
                    merged_df = pd.merge(
                        child_df_encoded, 
                        parent_df_encoded, 
                        left_on=child_key + '_encoded', 
                        right_on=parent_key + '_encoded', 
                        how='inner'
                    )
                    
                    print(f"ì¹´í…Œê³ ë¦¬ ì¸ì½”ë”© í›„ ë³‘í•© ì„±ê³µ: {len(merged_df)}í–‰ ìƒì„±")
                    
                    if len(merged_df) > 0:
                        # ì›ë³¸ í‚¤ ì´ë¦„ìœ¼ë¡œ ë³µêµ¬ (Parent í‚¤ ì‚¬ìš©)
                        merged_df[parent_key] = merged_df[parent_key + '_x']  # Parentì—ì„œ ì˜¨ ì›ë³¸ í‚¤
                        
                        # ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì œê±°
                        cols_to_drop = [col for col in merged_df.columns if col.endswith('_encoded') or col.endswith('_x') or col.endswith('_y')]
                        merged_df = merged_df.drop(columns=[col for col in cols_to_drop if col in merged_df.columns])
                        
                        # ì •ë ¬
                        if datetime_col and datetime_col in merged_df.columns:
                            merged_df = merged_df.sort_values(by=[parent_key, datetime_col]).reset_index(drop=True)
                        else:
                            merged_df = merged_df.sort_values(by=[parent_key]).reset_index(drop=True)
                        
                        return merged_df, parent_key, datetime_col
                    
        except Exception as e:
            print(f"ì¹´í…Œê³ ë¦¬ ì¸ì½”ë”© ì‹¤íŒ¨: {e}")
        
        # ë°©ë²• 2: ìˆœì„œ ê¸°ë°˜ ë§¤í•‘ ì‹œë„
        print("ë°©ë²• 2: ìˆœì„œ ê¸°ë°˜ í‚¤ ë§¤í•‘ ì‹œë„...")
        
        # Parentì™€ Childì˜ í‚¤ë¥¼ ì •ë ¬í•˜ì—¬ ìˆœì„œ ê¸°ë°˜ ë§¤í•‘ ì‹œë„
        parent_sorted_keys = sorted(list(parent_keys))
        child_sorted_keys = sorted(list(child_keys))
        
        min_keys = min(len(parent_sorted_keys), len(child_sorted_keys))
        
        if min_keys > 0:
            print(f"ìˆœì„œ ê¸°ë°˜ í‚¤ ë§¤í•‘ ì‹œë„: {min_keys}ê°œ í‚¤ ìŒ")
            
            # í‚¤ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ ìƒì„±
            key_mapping = {}
            for i in range(min_keys):
                key_mapping[child_sorted_keys[i]] = parent_sorted_keys[i]
            
            # Child í‚¤ë¥¼ Parent í‚¤ë¡œ ë§¤í•‘
            child_df_mapped = child_df.copy()
            child_df_mapped[child_key] = child_df_mapped[child_key].map(key_mapping)
            
            # ë§¤í•‘ë˜ì§€ ì•Šì€ ê°’ ì œê±°
            child_df_mapped = child_df_mapped.dropna(subset=[child_key])
            
            print(f"ë§¤í•‘ í›„ Child í…Œì´ë¸” í¬ê¸°: {len(child_df_mapped)} í–‰")
            print(f"ë§¤í•‘ í›„ Child í‚¤ ìƒ˜í”Œ: {child_df_mapped[child_key].head().tolist()}")
            
            if len(child_df_mapped) > 0:
                # ë§¤í•‘ëœ ë°ì´í„°ë¡œ ë³‘í•© ì¬ì‹œë„
                try:
                    merged_df = pd.merge(child_df_mapped, parent_df, left_on=child_key, right_on=parent_key, how='inner')
                    print(f"ë§¤í•‘ í›„ ë³‘í•© ì„±ê³µ: {len(merged_df)}í–‰ ìƒì„±")
                    
                    if merged_df.empty:
                        print(f"Warning: ë§¤í•‘ í›„ì—ë„ ë³‘í•© ê²°ê³¼ê°€ ë¹ˆ ë°ì´í„°í”„ë ˆì„ì…ë‹ˆë‹¤.")
                        return None
                    
                    # ì •ë ¬: datetimeì´ ìˆìœ¼ë©´ [parent_key, datetime_col], ì—†ìœ¼ë©´ [parent_key]ë§Œ
                    if datetime_col:
                        merged_df = merged_df.sort_values(by=[parent_key, datetime_col]).reset_index(drop=True)
                    else:
                        merged_df = merged_df.sort_values(by=[parent_key]).reset_index(drop=True)
                    
                    return merged_df, parent_key, datetime_col
                    
                except Exception as e:
                    print(f"ë§¤í•‘ í›„ ë³‘í•© ì‹¤íŒ¨: {e}")
                    return None
            else:
                print("ë§¤í•‘ í›„ì—ë„ ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return None
        else:
            print("í‚¤ ë§¤í•‘ ë¶ˆê°€ëŠ¥: ìœ íš¨í•œ í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
    
    # ì¤‘ë³µ í‚¤ í™•ì¸ (NaN ì œì™¸)
    parent_duplicated = parent_valid.duplicated().sum()
    child_duplicated = child_valid.duplicated().sum()
    print(f"Parent key ì¤‘ë³µ ê°œìˆ˜: {parent_duplicated}")
    print(f"Child key ì¤‘ë³µ ê°œìˆ˜: {child_duplicated}")
    
    if parent_duplicated > 0 or child_duplicated > 0:
        print("âš ï¸ WARNING: í‚¤ì— ì¤‘ë³µì´ ìˆì–´ Cartesian Productê°€ ë°œìƒí•  ìˆ˜ ìˆìŒ")
        
        # ì˜ˆìƒ ë³‘í•© ê²°ê³¼ í¬ê¸° ê³„ì‚°
        if len(common_keys) > 0:
            # ê° ê³µí†µ í‚¤ë³„ ì˜ˆìƒ ë§¤ì¹­ ìˆ˜ ê³„ì‚° (ì²˜ìŒ 10ê°œë§Œ ìƒ˜í”Œ)
            sample_keys = list(common_keys)[:10]
            total_expected = 0
            for key in sample_keys:
                parent_count = (parent_valid == key).sum()
                child_count = (child_valid == key).sum()
                total_expected += parent_count * child_count
            
            avg_per_key = total_expected / len(sample_keys) if len(sample_keys) > 0 else 0
            estimated_total = avg_per_key * len(common_keys)
            print(f"ì˜ˆìƒ ë³‘í•© ê²°ê³¼ í¬ê¸° (ì¶”ì •): {estimated_total:.0f} í–‰")
            
            if estimated_total > 1000000:  # 100ë§Œ í–‰ ì´ìƒì´ë©´ ê²½ê³ 
                print("ğŸš¨ ERROR: ì˜ˆìƒ ë³‘í•© ê²°ê³¼ê°€ ë„ˆë¬´ í¼. ë°ì´í„° ê´€ê³„ë¥¼ ì¬ê²€í†  í•„ìš”")
                print("ë³‘í•©ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                return None

    datetime_col, datetime_format = metadata.get_datetime_col_info(child_table_name)
        
    if datetime_col is None:
        print(f"!! {child_table_name}ì— datetime_colì´ ì—†ìŒ. PKey ê¸°ë°˜ ì •ë ¬ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    else:
        print(f"datetime_col: {datetime_col}, format: {datetime_format}")
    
    # datetime ì»¬ëŸ¼ ì²˜ë¦¬ (ìˆëŠ” ê²½ìš°ë§Œ)
    if datetime_col and datetime_col in child_df.columns:
        try:
            child_df[datetime_col] = pd.to_datetime(child_df[datetime_col], format=datetime_format)
        except Exception as e:
            print(f"Warning: datetime ë³€í™˜ ì‹¤íŒ¨ ({e}), datetime_colì„ Noneìœ¼ë¡œ ì„¤ì •")
            datetime_col = None

    try:
        merged_df = pd.merge(child_df, parent_df, left_on=child_key, right_on=parent_key, how='inner')
        print(f"ë³‘í•© ì„±ê³µ: {len(merged_df)}í–‰ ìƒì„±")
        
        if merged_df.empty:
            print(f"Warning: ë³‘í•© ê²°ê³¼ê°€ ë¹ˆ ë°ì´í„°í”„ë ˆì„ì…ë‹ˆë‹¤.")
            return None
            
    except KeyError as e:
        print(f"Error: ë³‘í•© ì¤‘ KeyError ë°œìƒ: {e}")
        print(f"í™•ì¸: parent_key='{parent_key}', child_key='{child_key}'")
        return None
    
    # ì •ë ¬: datetimeì´ ìˆìœ¼ë©´ [parent_key, datetime_col], ì—†ìœ¼ë©´ [parent_key]ë§Œ
    if datetime_col:
        merged_df = merged_df.sort_values(by=[parent_key, datetime_col]).reset_index(drop=True)
    else:
        merged_df = merged_df.sort_values(by=[parent_key]).reset_index(drop=True)
    
    return merged_df, parent_key, datetime_col

def calculate_lag1_differences(df, parent_key, datetime_col, numeric_col):
    """ê° ê°œì²´ë³„ë¡œ lag-1 ì°¨ë¶„ì„ ê³„ì‚°í•©ë‹ˆë‹¤. datetimeì´ ì—†ìœ¼ë©´ PKeyë¡œ ì •ë ¬"""
    all_diffs = []
    
    # ë¹ˆ ë°ì´í„°í”„ë ˆì„ ì²´í¬
    if df.empty:
        print(f"Warning: ë¹ˆ ë°ì´í„°í”„ë ˆì„ì´ ì „ë‹¬ë¨ - {numeric_col}")
        return np.array([])
    
    # ì»¬ëŸ¼ ì¡´ì¬ ì²´í¬
    if numeric_col not in df.columns:
        print(f"Warning: ì»¬ëŸ¼ '{numeric_col}'ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ")
        return np.array([])
    
    # parent_key ì¡´ì¬ ì²´í¬  
    if parent_key not in df.columns:
        print(f"Warning: Parent key '{parent_key}'ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ")
        return np.array([])
    
    try:
        # datetime ì»¬ëŸ¼ì´ ìˆëŠ” ê²½ìš°: ê¸°ì¡´ ë°©ì‹ (fkey, date ì •ë ¬)
        print(f"{parent_key}, {datetime_col}ë¡œ ì •ë ¬í•˜ì—¬ ì‹œê³„ì—´ ì°¨ì´ ê³„ì‚°")
        
        # datetime ì»¬ëŸ¼ ì¡´ì¬ ì²´í¬
        if datetime_col not in df.columns:
            print(f"Warning: Datetime ì»¬ëŸ¼ '{datetime_col}'ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ")
            return np.array([])    
            
        df_sorted = df.sort_values([parent_key, datetime_col]).reset_index(drop=True)
        
        for _, group in df_sorted.groupby(parent_key):
            if len(group) < 2:
                continue
            
            # ë‚ ì§œ ìˆœìœ¼ë¡œ ì •ë ¬ëœ ê°’ë“¤ì˜ ì°¨ì´ ê³„ì‚°
            values = group[numeric_col].dropna()
            if len(values) < 2:
                continue
                
            # lag-1 ì°¨ë¶„ ê³„ì‚°
            diffs = values.diff().dropna()
            all_diffs.extend(diffs.tolist())
    except Exception as e:
        print(f"no datetime column detected: {e}")
    
    if len(all_diffs) == 0:
        print(f"Warning: {numeric_col}ì— ëŒ€í•œ lag-1 ì°¨ë¶„ì´ ê³„ì‚°ë˜ì§€ ì•ŠìŒ")
    
    return np.array(all_diffs)